{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import our dependencies\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "import keras_tuner as kt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_rows = 500\n",
    "pd.options.display.max_columns = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset():\n",
    "    \"\"\" Reads dataset csv and returns pandas dataframe \"\"\"\n",
    "    \n",
    "    filepath = \"Resources/charity_data.csv\"\n",
    "\n",
    "    df = pd.read_csv(filepath, encoding=\"utf-8\", low_memory=False)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_dataset(a_df):\n",
    "    \"\"\" Returns deduped, na-dropped, index-reset dataframe \"\"\"    \n",
    "    \n",
    "    a_df = a_df.drop_duplicates()   \n",
    "        \n",
    "    a_df = a_df.dropna()\n",
    "        \n",
    "    a_df = a_df.reset_index(drop=True)\n",
    "    \n",
    "    return a_df   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def examine_dataset(a_df):\n",
    "    \"\"\" Provides summary info and visualizations of dataset \"\"\"\n",
    "    \n",
    "    print(a_df.info())\n",
    "           \n",
    "    # Determine the number of unique values in each column.\n",
    "\n",
    "    for col in a_df.columns:\n",
    "        print(f\"{col} \\n{a_df[col].value_counts()}\\n\\n\")   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = clean_dataset(load_dataset())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 34299 entries, 0 to 34298\n",
      "Data columns (total 12 columns):\n",
      " #   Column                  Non-Null Count  Dtype \n",
      "---  ------                  --------------  ----- \n",
      " 0   EIN                     34299 non-null  int64 \n",
      " 1   NAME                    34299 non-null  object\n",
      " 2   APPLICATION_TYPE        34299 non-null  object\n",
      " 3   AFFILIATION             34299 non-null  object\n",
      " 4   CLASSIFICATION          34299 non-null  object\n",
      " 5   USE_CASE                34299 non-null  object\n",
      " 6   ORGANIZATION            34299 non-null  object\n",
      " 7   STATUS                  34299 non-null  int64 \n",
      " 8   INCOME_AMT              34299 non-null  object\n",
      " 9   SPECIAL_CONSIDERATIONS  34299 non-null  object\n",
      " 10  ASK_AMT                 34299 non-null  int64 \n",
      " 11  IS_SUCCESSFUL           34299 non-null  int64 \n",
      "dtypes: int64(4), object(8)\n",
      "memory usage: 3.1+ MB\n",
      "None\n",
      "EIN \n",
      "10520599     1\n",
      "626274659    1\n",
      "630475330    1\n",
      "630416100    1\n",
      "630357662    1\n",
      "            ..\n",
      "383880377    1\n",
      "383876652    1\n",
      "383874900    1\n",
      "383871370    1\n",
      "996086871    1\n",
      "Name: EIN, Length: 34299, dtype: int64\n",
      "\n",
      "\n",
      "NAME \n",
      "PARENT BOOSTER USA INC                                                  1260\n",
      "TOPS CLUB INC                                                            765\n",
      "UNITED STATES BOWLING CONGRESS INC                                       700\n",
      "WASHINGTON STATE UNIVERSITY                                              492\n",
      "AMATEUR ATHLETIC UNION OF THE UNITED STATES INC                          408\n",
      "                                                                        ... \n",
      "ST LOUIS SLAM WOMENS FOOTBALL                                              1\n",
      "AIESEC ALUMNI IBEROAMERICA CORP                                            1\n",
      "WEALLBLEEDRED ORG INC                                                      1\n",
      "AMERICAN SOCIETY FOR STANDARDS IN MEDIUMSHIP & PSYCHICAL INVESTIGATI       1\n",
      "WATERHOUSE CHARITABLE TR                                                   1\n",
      "Name: NAME, Length: 19568, dtype: int64\n",
      "\n",
      "\n",
      "APPLICATION_TYPE \n",
      "T3     27037\n",
      "T4      1542\n",
      "T6      1216\n",
      "T5      1173\n",
      "T19     1065\n",
      "T8       737\n",
      "T7       725\n",
      "T10      528\n",
      "T9       156\n",
      "T13       66\n",
      "T12       27\n",
      "T2        16\n",
      "T25        3\n",
      "T14        3\n",
      "T29        2\n",
      "T15        2\n",
      "T17        1\n",
      "Name: APPLICATION_TYPE, dtype: int64\n",
      "\n",
      "\n",
      "AFFILIATION \n",
      "Independent         18480\n",
      "CompanySponsored    15705\n",
      "Family/Parent          64\n",
      "National               33\n",
      "Regional               13\n",
      "Other                   4\n",
      "Name: AFFILIATION, dtype: int64\n",
      "\n",
      "\n",
      "CLASSIFICATION \n",
      "C1000    17326\n",
      "C2000     6074\n",
      "C1200     4837\n",
      "C3000     1918\n",
      "C2100     1883\n",
      "C7000      777\n",
      "C1700      287\n",
      "C4000      194\n",
      "C5000      116\n",
      "C1270      114\n",
      "C2700      104\n",
      "C2800       95\n",
      "C7100       75\n",
      "C1300       58\n",
      "C1280       50\n",
      "C1230       36\n",
      "C1400       34\n",
      "C7200       32\n",
      "C2300       32\n",
      "C1240       30\n",
      "C8000       20\n",
      "C7120       18\n",
      "C1500       16\n",
      "C1800       15\n",
      "C6000       15\n",
      "C1250       14\n",
      "C8200       11\n",
      "C1238       10\n",
      "C1278       10\n",
      "C1235        9\n",
      "C1237        9\n",
      "C7210        7\n",
      "C2400        6\n",
      "C1720        6\n",
      "C4100        6\n",
      "C1257        5\n",
      "C1600        5\n",
      "C1260        3\n",
      "C2710        3\n",
      "C0           3\n",
      "C3200        2\n",
      "C1234        2\n",
      "C1246        2\n",
      "C1267        2\n",
      "C1256        2\n",
      "C2190        1\n",
      "C4200        1\n",
      "C2600        1\n",
      "C5200        1\n",
      "C1370        1\n",
      "C1248        1\n",
      "C6100        1\n",
      "C1820        1\n",
      "C1900        1\n",
      "C1236        1\n",
      "C3700        1\n",
      "C2570        1\n",
      "C1580        1\n",
      "C1245        1\n",
      "C2500        1\n",
      "C1570        1\n",
      "C1283        1\n",
      "C2380        1\n",
      "C1732        1\n",
      "C1728        1\n",
      "C2170        1\n",
      "C4120        1\n",
      "C8210        1\n",
      "C2561        1\n",
      "C4500        1\n",
      "C2150        1\n",
      "Name: CLASSIFICATION, dtype: int64\n",
      "\n",
      "\n",
      "USE_CASE \n",
      "Preservation     28095\n",
      "ProductDev        5671\n",
      "CommunityServ      384\n",
      "Heathcare          146\n",
      "Other                3\n",
      "Name: USE_CASE, dtype: int64\n",
      "\n",
      "\n",
      "ORGANIZATION \n",
      "Trust           23515\n",
      "Association     10255\n",
      "Co-operative      486\n",
      "Corporation        43\n",
      "Name: ORGANIZATION, dtype: int64\n",
      "\n",
      "\n",
      "STATUS \n",
      "1    34294\n",
      "0        5\n",
      "Name: STATUS, dtype: int64\n",
      "\n",
      "\n",
      "INCOME_AMT \n",
      "0                24388\n",
      "25000-99999       3747\n",
      "100000-499999     3374\n",
      "1M-5M              955\n",
      "1-9999             728\n",
      "10000-24999        543\n",
      "10M-50M            240\n",
      "5M-10M             185\n",
      "50M+               139\n",
      "Name: INCOME_AMT, dtype: int64\n",
      "\n",
      "\n",
      "SPECIAL_CONSIDERATIONS \n",
      "N    34272\n",
      "Y       27\n",
      "Name: SPECIAL_CONSIDERATIONS, dtype: int64\n",
      "\n",
      "\n",
      "ASK_AMT \n",
      "5000        25398\n",
      "10478           3\n",
      "15583           3\n",
      "63981           3\n",
      "6725            3\n",
      "            ...  \n",
      "5371754         1\n",
      "30060           1\n",
      "43091152        1\n",
      "18683           1\n",
      "36500179        1\n",
      "Name: ASK_AMT, Length: 8747, dtype: int64\n",
      "\n",
      "\n",
      "IS_SUCCESSFUL \n",
      "1    18261\n",
      "0    16038\n",
      "Name: IS_SUCCESSFUL, dtype: int64\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "examine_dataset(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the non-beneficial columns\n",
    "\n",
    "df = df.drop(columns=[\"EIN\", \"NAME\", \"STATUS\", \"SPECIAL_CONSIDERATIONS\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_cats(a_col, a_cutoff):\n",
    "    \"\"\" Inputs are a series and a cutoff value for 'Other' \"\"\"\n",
    "    \n",
    "    print(f\"BEFORE: \\n\\n{df[a_col].value_counts()}\\n\\n\")\n",
    "\n",
    "    types_to_replace = (df[a_col].value_counts().loc[lambda x: x < int(a_cutoff)]).keys().tolist()\n",
    "\n",
    "    for code in types_to_replace:        \n",
    "        df[a_col] = df[a_col].replace(code, \"Other\")\n",
    "\n",
    "    # Check to make sure binning was successful\n",
    "\n",
    "    print(f\"AFTER: \\n\\n{df[a_col].value_counts()}\\n\\n\")   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEFORE: \n",
      "\n",
      "Independent         18480\n",
      "CompanySponsored    15705\n",
      "Family/Parent          64\n",
      "National               33\n",
      "Regional               13\n",
      "Other                   4\n",
      "Name: AFFILIATION, dtype: int64\n",
      "\n",
      "\n",
      "AFTER: \n",
      "\n",
      "Independent         18480\n",
      "CompanySponsored    15705\n",
      "Other                 114\n",
      "Name: AFFILIATION, dtype: int64\n",
      "\n",
      "\n",
      "BEFORE: \n",
      "\n",
      "T3     27037\n",
      "T4      1542\n",
      "T6      1216\n",
      "T5      1173\n",
      "T19     1065\n",
      "T8       737\n",
      "T7       725\n",
      "T10      528\n",
      "T9       156\n",
      "T13       66\n",
      "T12       27\n",
      "T2        16\n",
      "T25        3\n",
      "T14        3\n",
      "T29        2\n",
      "T15        2\n",
      "T17        1\n",
      "Name: APPLICATION_TYPE, dtype: int64\n",
      "\n",
      "\n",
      "AFTER: \n",
      "\n",
      "T3       27037\n",
      "Other     2266\n",
      "T4        1542\n",
      "T6        1216\n",
      "T5        1173\n",
      "T19       1065\n",
      "Name: APPLICATION_TYPE, dtype: int64\n",
      "\n",
      "\n",
      "BEFORE: \n",
      "\n",
      "5000        25398\n",
      "10478           3\n",
      "15583           3\n",
      "63981           3\n",
      "6725            3\n",
      "            ...  \n",
      "5371754         1\n",
      "30060           1\n",
      "43091152        1\n",
      "18683           1\n",
      "36500179        1\n",
      "Name: ASK_AMT, Length: 8747, dtype: int64\n",
      "\n",
      "\n",
      "AFTER: \n",
      "\n",
      "5000     25398\n",
      "Other     8901\n",
      "Name: ASK_AMT, dtype: int64\n",
      "\n",
      "\n",
      "BEFORE: \n",
      "\n",
      "C1000    17326\n",
      "C2000     6074\n",
      "C1200     4837\n",
      "C3000     1918\n",
      "C2100     1883\n",
      "C7000      777\n",
      "C1700      287\n",
      "C4000      194\n",
      "C5000      116\n",
      "C1270      114\n",
      "C2700      104\n",
      "C2800       95\n",
      "C7100       75\n",
      "C1300       58\n",
      "C1280       50\n",
      "C1230       36\n",
      "C1400       34\n",
      "C7200       32\n",
      "C2300       32\n",
      "C1240       30\n",
      "C8000       20\n",
      "C7120       18\n",
      "C1500       16\n",
      "C1800       15\n",
      "C6000       15\n",
      "C1250       14\n",
      "C8200       11\n",
      "C1238       10\n",
      "C1278       10\n",
      "C1235        9\n",
      "C1237        9\n",
      "C7210        7\n",
      "C2400        6\n",
      "C1720        6\n",
      "C4100        6\n",
      "C1257        5\n",
      "C1600        5\n",
      "C1260        3\n",
      "C2710        3\n",
      "C0           3\n",
      "C3200        2\n",
      "C1234        2\n",
      "C1246        2\n",
      "C1267        2\n",
      "C1256        2\n",
      "C2190        1\n",
      "C4200        1\n",
      "C2600        1\n",
      "C5200        1\n",
      "C1370        1\n",
      "C1248        1\n",
      "C6100        1\n",
      "C1820        1\n",
      "C1900        1\n",
      "C1236        1\n",
      "C3700        1\n",
      "C2570        1\n",
      "C1580        1\n",
      "C1245        1\n",
      "C2500        1\n",
      "C1570        1\n",
      "C1283        1\n",
      "C2380        1\n",
      "C1732        1\n",
      "C1728        1\n",
      "C2170        1\n",
      "C4120        1\n",
      "C8210        1\n",
      "C2561        1\n",
      "C4500        1\n",
      "C2150        1\n",
      "Name: CLASSIFICATION, dtype: int64\n",
      "\n",
      "\n",
      "AFTER: \n",
      "\n",
      "C1000    17326\n",
      "C2000     6074\n",
      "C1200     4837\n",
      "Other     2261\n",
      "C3000     1918\n",
      "C2100     1883\n",
      "Name: CLASSIFICATION, dtype: int64\n",
      "\n",
      "\n",
      "BEFORE: \n",
      "\n",
      "0                24388\n",
      "25000-99999       3747\n",
      "100000-499999     3374\n",
      "1M-5M              955\n",
      "1-9999             728\n",
      "10000-24999        543\n",
      "10M-50M            240\n",
      "5M-10M             185\n",
      "50M+               139\n",
      "Name: INCOME_AMT, dtype: int64\n",
      "\n",
      "\n",
      "AFTER: \n",
      "\n",
      "0                24388\n",
      "25000-99999       3747\n",
      "100000-499999     3374\n",
      "Other             2790\n",
      "Name: INCOME_AMT, dtype: int64\n",
      "\n",
      "\n",
      "BEFORE: \n",
      "\n",
      "Trust           23515\n",
      "Association     10255\n",
      "Co-operative      486\n",
      "Corporation        43\n",
      "Name: ORGANIZATION, dtype: int64\n",
      "\n",
      "\n",
      "AFTER: \n",
      "\n",
      "Trust          23515\n",
      "Association    10255\n",
      "Other            529\n",
      "Name: ORGANIZATION, dtype: int64\n",
      "\n",
      "\n",
      "BEFORE: \n",
      "\n",
      "Preservation     28095\n",
      "ProductDev        5671\n",
      "CommunityServ      384\n",
      "Heathcare          146\n",
      "Other                3\n",
      "Name: USE_CASE, dtype: int64\n",
      "\n",
      "\n",
      "AFTER: \n",
      "\n",
      "Preservation    28095\n",
      "ProductDev       5671\n",
      "Other             533\n",
      "Name: USE_CASE, dtype: int64\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "reduce_cats(\"AFFILIATION\", 15_000)\n",
    "\n",
    "reduce_cats(\"APPLICATION_TYPE\", 1000)\n",
    "\n",
    "reduce_cats(\"ASK_AMT\", 25_000)\n",
    "\n",
    "reduce_cats(\"CLASSIFICATION\", 1000)\n",
    "\n",
    "reduce_cats(\"INCOME_AMT\", 3000)\n",
    "\n",
    "reduce_cats(\"ORGANIZATION\", 10_000)\n",
    "\n",
    "reduce_cats(\"USE_CASE\", 5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_df(a_df):\n",
    "    \"\"\" Returns one-hot encoded dataframe \"\"\"\n",
    "    \n",
    "    categorical_list = a_df.dtypes[a_df.dtypes == \"object\"].index.tolist() \n",
    "    \n",
    "    print(f\"CATEGORIES FOR EACH CATEGORICAL FEATURE ENCODED:\\n\\n{a_df[categorical_list].nunique()}\\n\\n\")\n",
    "    \n",
    "    concat_list = []\n",
    "    \n",
    "    for categorical in categorical_list:\n",
    "        \n",
    "        concat_list.append(pd.get_dummies(a_df[categorical], prefix=categorical, prefix_sep='_'))        \n",
    "    \n",
    "    concat_list.append(a_df[\"IS_SUCCESSFUL\"])\n",
    "\n",
    "    return pd.concat(concat_list, axis=1)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CATEGORIES FOR EACH CATEGORICAL FEATURE ENCODED:\n",
      "\n",
      "APPLICATION_TYPE    6\n",
      "AFFILIATION         3\n",
      "CLASSIFICATION      6\n",
      "USE_CASE            3\n",
      "ORGANIZATION        3\n",
      "INCOME_AMT          4\n",
      "ASK_AMT             2\n",
      "dtype: int64\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "enc_df = encode_df(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_process(a_df):\n",
    "    \"\"\" Make X,y ... train_test_split ... scale, fit and transform \"\"\"\n",
    "    \n",
    "    # Split our preprocessed data into our features and target arrays\n",
    "\n",
    "    y = enc_df[\"IS_SUCCESSFUL\"].values\n",
    "    X = enc_df.drop([\"IS_SUCCESSFUL\"], axis=1).values\n",
    "\n",
    "    # Split the preprocessed data into a training and testing dataset\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42) \n",
    "    \n",
    "    # Create a StandardScaler instances\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "\n",
    "    # scaler = MinMaxScaler()\n",
    "\n",
    "    # Fit the StandardScaler\n",
    "\n",
    "    X_scaler = scaler.fit(X_train)\n",
    "\n",
    "    # Scale the data\n",
    "\n",
    "    X_train_scaled = X_scaler.transform(X_train)\n",
    "    X_test_scaled = X_scaler.transform(X_test)\n",
    "\n",
    "    print(f\"TRAIN SCALED SHAPE: {X_train_scaled.shape}\")\n",
    "    print(f\"TEST SCALED SHAPE: {X_test_scaled.shape}\")\n",
    "\n",
    "    input_dim = X_train_scaled.shape[1]  \n",
    "    \n",
    "    return input_dim, X_train_scaled, X_test_scaled, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN SCALED SHAPE: (25724, 27)\n",
      "TEST SCALED SHAPE: (8575, 27)\n"
     ]
    }
   ],
   "source": [
    "input_dim, X_train_scaled, X_test_scaled, y_train, y_test = pre_process(enc_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compile, Train and Evaluate the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_nn(input_dim=14, num_layers=2, num_units=5, num_epochs=5):\n",
    "    \"\"\" Makes sequential nn, compiles, fits, saves, and reports on loss and accuracy \"\"\"    \n",
    "    \n",
    "    nn = tf.keras.models.Sequential()\n",
    "\n",
    "    # First layer \n",
    "    \n",
    "    nn.add(tf.keras.layers.Dense(units=num_units, input_dim=input_dim, activation=\"relu\"))\n",
    "    \n",
    "    # Hidden layers\n",
    "    \n",
    "    for layer in range(1, num_layers):\n",
    "        \n",
    "        nn.add(tf.keras.layers.Dense(units=num_units, activation=\"relu\"))\n",
    "\n",
    "    # Output layer\n",
    "\n",
    "    nn.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "    \n",
    "    nn.summary()\n",
    "    \n",
    "    nn.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"]) \n",
    "    \n",
    "    fit_model = nn.fit(X_train_scaled, y_train, epochs=num_epochs)   \n",
    "    \n",
    "    model_loss, model_accuracy = nn.evaluate(X_test_scaled, y_test, verbose=2)\n",
    "    \n",
    "    print(f\"\\n\\nLoss: {model_loss}, Accuracy: {model_accuracy}\")    \n",
    "\n",
    "    nn.save(\"AlphabetSoupCharity.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_nn(27, 2, 75, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a method that creates a new Sequential model with hyperparameter options\n",
    "\n",
    "def create_model(hp):\n",
    "    \n",
    "    # Instantiate a Sequential model\n",
    "    \n",
    "    nn_model = tf.keras.models.Sequential()\n",
    "\n",
    "    # Allow kerastuner to decide which activation function to use in hidden layers.\n",
    "    \n",
    "    activation = hp.Choice('activation', ['relu','tanh','sigmoid'])\n",
    "    \n",
    "    # Allow kerastuner to decide the number of neurons in first layer and also\n",
    "    # the activation function. \n",
    "    \n",
    "    nn_model.add(tf.keras.layers.Dense(units=hp.Int('first_units',\n",
    "        min_value=1,\n",
    "        max_value=10,\n",
    "        step=2), activation=activation, input_dim=27))\n",
    "\n",
    "    # Allow kerastuner to decide the number of hidden layers and number of \n",
    "    # neurons in each one\n",
    "    \n",
    "    for i in range(hp.Int('num_layers', 1, 4)):\n",
    "        nn_model.add(tf.keras.layers.Dense(units=hp.Int('units_' + str(i),\n",
    "            min_value=1,\n",
    "            max_value=10,\n",
    "            step=2),\n",
    "            activation=activation))\n",
    "    \n",
    "    # Define the output layer\n",
    "    nn_model.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "    # Compile the model\n",
    "    nn_model.compile(loss=\"binary_crossentropy\", optimizer='adam', metrics=[\"accuracy\"])\n",
    "    \n",
    "    return nn_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best():\n",
    "    \"\"\" Uses keras-tuner to find best model specs \"\"\"\n",
    "    \n",
    "    tuner = kt.Hyperband(\n",
    "        create_model,\n",
    "        objective=\"val_accuracy\",\n",
    "        max_epochs=10,\n",
    "        hyperband_iterations=2)\n",
    "    \n",
    "    # Run the kerastuner search for best hyperparameters\n",
    "\n",
    "    tuner.search(X_train_scaled, y_train, epochs=20, validation_data=(X_test_scaled, y_test))\n",
    "    \n",
    "     # Get best model hyperparameters\n",
    " \n",
    "    best_hyper = tuner.get_best_hyperparameters(1)[0]\n",
    "\n",
    "    print(best_hyper.values)\n",
    "    \n",
    "     # Evaluate best model against full test data\n",
    " \n",
    "    best_model = tuner.get_best_models(1)[0]\n",
    "    model_loss, model_accuracy = best_model.evaluate(X_test_scaled, y_test, verbose=2)\n",
    "\n",
    "    print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")\n",
    "    \n",
    "     # Summarize the best model\n",
    " \n",
    "    print(best_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reloading Oracle from existing project .\\untitled_project\\oracle.json\n",
      "INFO:tensorflow:Reloading Tuner from .\\untitled_project\\tuner0.json\n",
      "INFO:tensorflow:Oracle triggered exit\n",
      "{'activation': 'tanh', 'first_units': 9, 'num_layers': 4, 'units_0': 7, 'units_1': 1, 'units_2': 9, 'units_3': 7, 'units_4': 1, 'units_5': 3, 'tuner/epochs': 20, 'tuner/initial_epoch': 7, 'tuner/bracket': 1, 'tuner/round': 1, 'tuner/trial_id': '0049'}\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Received incompatible tensor with shape (35, 9) when attempting to restore variable with shape (27, 9) and name layer_with_weights-0/kernel/.ATTRIBUTES/VARIABLE_VALUE.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [17]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mfind_best\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[1;32mIn [16]\u001b[0m, in \u001b[0;36mfind_best\u001b[1;34m()\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28mprint\u001b[39m(best_hyper\u001b[38;5;241m.\u001b[39mvalues)\n\u001b[0;32m     20\u001b[0m  \u001b[38;5;66;03m# Evaluate best model against full test data\u001b[39;00m\n\u001b[1;32m---> 22\u001b[0m best_model \u001b[38;5;241m=\u001b[39m \u001b[43mtuner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_best_models\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m     23\u001b[0m model_loss, model_accuracy \u001b[38;5;241m=\u001b[39m best_model\u001b[38;5;241m.\u001b[39mevaluate(X_test_scaled, y_test, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_loss\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_accuracy\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\PythonData38\\lib\\site-packages\\keras_tuner\\engine\\tuner.py:374\u001b[0m, in \u001b[0;36mTuner.get_best_models\u001b[1;34m(self, num_models)\u001b[0m\n\u001b[0;32m    356\u001b[0m \u001b[38;5;124;03m\"\"\"Returns the best model(s), as determined by the tuner's objective.\u001b[39;00m\n\u001b[0;32m    357\u001b[0m \n\u001b[0;32m    358\u001b[0m \u001b[38;5;124;03mThe models are loaded with the weights corresponding to\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    371\u001b[0m \u001b[38;5;124;03m    List of trained model instances sorted from the best to the worst.\u001b[39;00m\n\u001b[0;32m    372\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    373\u001b[0m \u001b[38;5;66;03m# Method only exists in this class for the docstring override.\u001b[39;00m\n\u001b[1;32m--> 374\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mTuner\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_best_models\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnum_models\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\PythonData38\\lib\\site-packages\\keras_tuner\\engine\\base_tuner.py:296\u001b[0m, in \u001b[0;36mBaseTuner.get_best_models\u001b[1;34m(self, num_models)\u001b[0m\n\u001b[0;32m    281\u001b[0m \u001b[38;5;124;03m\"\"\"Returns the best model(s), as determined by the objective.\u001b[39;00m\n\u001b[0;32m    282\u001b[0m \n\u001b[0;32m    283\u001b[0m \u001b[38;5;124;03mThis method is for querying the models trained during the search.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    293\u001b[0m \u001b[38;5;124;03m    List of trained models sorted from the best to the worst.\u001b[39;00m\n\u001b[0;32m    294\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    295\u001b[0m best_trials \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moracle\u001b[38;5;241m.\u001b[39mget_best_trials(num_models)\n\u001b[1;32m--> 296\u001b[0m models \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mload_model(trial) \u001b[38;5;28;01mfor\u001b[39;00m trial \u001b[38;5;129;01min\u001b[39;00m best_trials]\n\u001b[0;32m    297\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m models\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\PythonData38\\lib\\site-packages\\keras_tuner\\engine\\base_tuner.py:296\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    281\u001b[0m \u001b[38;5;124;03m\"\"\"Returns the best model(s), as determined by the objective.\u001b[39;00m\n\u001b[0;32m    282\u001b[0m \n\u001b[0;32m    283\u001b[0m \u001b[38;5;124;03mThis method is for querying the models trained during the search.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    293\u001b[0m \u001b[38;5;124;03m    List of trained models sorted from the best to the worst.\u001b[39;00m\n\u001b[0;32m    294\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    295\u001b[0m best_trials \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moracle\u001b[38;5;241m.\u001b[39mget_best_trials(num_models)\n\u001b[1;32m--> 296\u001b[0m models \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m trial \u001b[38;5;129;01min\u001b[39;00m best_trials]\n\u001b[0;32m    297\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m models\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\PythonData38\\lib\\site-packages\\keras_tuner\\engine\\tuner.py:305\u001b[0m, in \u001b[0;36mTuner.load_model\u001b[1;34m(self, trial)\u001b[0m\n\u001b[0;32m    302\u001b[0m \u001b[38;5;66;03m# Reload best checkpoint.\u001b[39;00m\n\u001b[0;32m    303\u001b[0m \u001b[38;5;66;03m# Only load weights to avoid loading `custom_objects`.\u001b[39;00m\n\u001b[0;32m    304\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m maybe_distribute(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdistribution_strategy):\n\u001b[1;32m--> 305\u001b[0m     \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_weights\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_checkpoint_fname\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrial_id\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    306\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m model\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\PythonData38\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\PythonData38\\lib\\site-packages\\tensorflow\\python\\training\\saving\\saveable_object_util.py:135\u001b[0m, in \u001b[0;36mResourceVariableSaveable.restore\u001b[1;34m(self, restored_tensors, restored_shapes)\u001b[0m\n\u001b[0;32m    132\u001b[0m   assigned_variable \u001b[38;5;241m=\u001b[39m resource_variable_ops\u001b[38;5;241m.\u001b[39mshape_safe_assign_variable_handle(\n\u001b[0;32m    133\u001b[0m       \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandle_op, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_var_shape, restored_tensor)\n\u001b[0;32m    134\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m--> 135\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    136\u001b[0m       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReceived incompatible tensor with shape \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrestored_tensor\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    137\u001b[0m       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwhen attempting to restore variable with shape \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_var_shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    138\u001b[0m       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mand name \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[0;32m    139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m assigned_variable\n",
      "\u001b[1;31mValueError\u001b[0m: Received incompatible tensor with shape (35, 9) when attempting to restore variable with shape (27, 9) and name layer_with_weights-0/kernel/.ATTRIBUTES/VARIABLE_VALUE."
     ]
    }
   ],
   "source": [
    "find_best()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model - deep neural net, i.e., the number of input features and hidden nodes for each layer.\n",
    "\n",
    "nn = tf.keras.models.Sequential()\n",
    "\n",
    "# First hidden layer\n",
    "\n",
    "nn.add(tf.keras.layers.Dense(units=9, input_dim=35, activation=\"tanh\"))\n",
    "\n",
    "# Second hidden layer\n",
    "\n",
    "nn.add(tf.keras.layers.Dense(units=7, activation=\"tanh\"))\n",
    "\n",
    "# Third hidden layer\n",
    "\n",
    "nn.add(tf.keras.layers.Dense(units=1, activation=\"tanh\"))\n",
    "\n",
    "# Fourth hidden layer\n",
    "\n",
    "nn.add(tf.keras.layers.Dense(units=9, activation=\"tanh\"))\n",
    "\n",
    "# Fifth hidden layer\n",
    "\n",
    "nn.add(tf.keras.layers.Dense(units=7, activation=\"tanh\"))\n",
    "\n",
    "\n",
    "# Output layer\n",
    "\n",
    "nn.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "# Check the structure of the model\n",
    "\n",
    "nn.summary()\n",
    "\n",
    "# Compile the model\n",
    "\n",
    "nn.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"]) \n",
    "\n",
    "# Train the model\n",
    "\n",
    "fit_model = nn.fit(X_train_scaled, y_train, epochs=50) \n",
    "\n",
    "# Evaluate the model using the test data\n",
    "\n",
    "model_loss, model_accuracy = nn.evaluate(X_test_scaled,y_test,verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")\n",
    "\n",
    "# Export our model to HDF5 file\n",
    "\n",
    "nn.save(\"nn_optimized.h5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
